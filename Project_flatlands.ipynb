{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization:"
      ],
      "metadata": {
        "id": "LwxO1FtoSB_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "0XU6xC3MOsVu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyXG9byjN8ux",
        "outputId": "042db55e-7793-4d7d-8fc4-9ed1e8710b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path1 = '/content/drive/MyDrive/VU/project_flatlands/flatland_train.npz'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WTCgDTnlR_s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(path1)\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "y[y != 0] -= 2    # Correct labels so that triangle is mapped to class 1\n",
        "X = X / 255.      # Scale down to range [0, 1]"
      ],
      "metadata": {
        "id": "j3Pd5sjjO9qa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD7HR1SmP0ss",
        "outputId": "8d6753e8-4db9-444e-ed07-75077922506a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 50, 50)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLBCaf9hpz6H",
        "outputId": "944de786-df1b-4cb2-809c-0da54bb73933"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 4. 3. ... 4. 4. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_value = y.min()\n",
        "max_value = y.max()\n",
        "print(min_value)\n",
        "print(max_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjikk3I3VdAR",
        "outputId": "74d3f8da-54c6-43bf-8e65-abc02a267d97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation:"
      ],
      "metadata": {
        "id": "m9W-wJYESFrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlatLensDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Custom dataset initialization.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Generates one sample of data.\n",
        "        \"\"\"\n",
        "        # Loading and getting the image\n",
        "        image = self.X[idx]\n",
        "        # Add a channel dimension (1, 50, 50), for grayscale images\n",
        "        image = image.reshape(1, 50, 50)\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "        # Get label\n",
        "        label = self.y[idx]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "N2SZKkUMU70m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Splits the dataset into training and testing sets based on the specified ratio.\n",
        "\n",
        "    :param X: The input features.\n",
        "    :param y: The target labels.\n",
        "    :param train_ratio: Ratio of the training set size to the total dataset size.\n",
        "    :return: Two datasets, one for training and one for testing.\n",
        "    \"\"\"\n",
        "    # Create the full dataset\n",
        "    full_dataset = FlatLensDataset(X, y)\n",
        "\n",
        "    # Calculate the size of training and testing datasets\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(total_size * train_ratio)\n",
        "    test_size = total_size - train_size\n",
        "\n",
        "    # Split the dataset\n",
        "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# Usage example\n",
        "train_ratio = 0.8  # 80% training, 20% testing\n",
        "train_dataset, test_dataset = split_dataset(X, y, train_ratio)\n",
        "\n",
        "# Now create DataLoaders for both datasets\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "iZOdAJ8dTy6w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model:"
      ],
      "metadata": {
        "id": "67bfDg9HVEA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) # for grayscale images\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 12 * 12, 128) # Adjust the size\n",
        "        self.fc2 = nn.Linear(128, 5) # 5 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 12 * 12) # Flatten the output for the fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        if not self.training:\n",
        "            # In evaluation mode, return the predicted class directly\n",
        "            return torch.argmax(x, dim=1)\n",
        "        return x  # In training mode, return logits\n"
      ],
      "metadata": {
        "id": "1t8OjBZBU-ag"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train loop:"
      ],
      "metadata": {
        "id": "PtJ8BmOCXa0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialize model\"\n",
        "\n",
        "# Check if CUDA is available and set the device to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Move the model to the specified device\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM8oELF5aApk",
        "outputId": "5bf73ce9-f8e4-4cd9-c124-0bbc5e7433eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25  # Set the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PuVoXAUXe3B",
        "outputId": "42dd0381-f976-497e-d215-a220c609f55f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Loss: 1.1916\n",
            "Epoch [2/25], Loss: 1.0745\n",
            "Epoch [3/25], Loss: 0.9985\n",
            "Epoch [4/25], Loss: 0.7813\n",
            "Epoch [5/25], Loss: 0.8154\n",
            "Epoch [6/25], Loss: 0.6428\n",
            "Epoch [7/25], Loss: 0.5147\n",
            "Epoch [8/25], Loss: 0.6266\n",
            "Epoch [9/25], Loss: 0.3904\n",
            "Epoch [10/25], Loss: 0.4598\n",
            "Epoch [11/25], Loss: 0.2070\n",
            "Epoch [12/25], Loss: 0.2149\n",
            "Epoch [13/25], Loss: 0.1602\n",
            "Epoch [14/25], Loss: 0.2904\n",
            "Epoch [15/25], Loss: 0.1329\n",
            "Epoch [16/25], Loss: 0.1257\n",
            "Epoch [17/25], Loss: 0.2970\n",
            "Epoch [18/25], Loss: 0.1030\n",
            "Epoch [19/25], Loss: 0.1473\n",
            "Epoch [20/25], Loss: 0.1554\n",
            "Epoch [21/25], Loss: 0.1221\n",
            "Epoch [22/25], Loss: 0.1062\n",
            "Epoch [23/25], Loss: 0.2004\n",
            "Epoch [24/25], Loss: 0.0663\n",
            "Epoch [25/25], Loss: 0.1075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "hB7tF9XOjEmV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test model:"
      ],
      "metadata": {
        "id": "gP9WZ1D9jKKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire model\n",
        "model = torch.load('model.pth')\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to track test accuracy and total number of test samples\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Disable gradient computation since we are in evaluation mode\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move the data to the device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass to get outputs\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Get predictions\n",
        "        predicted = outputs.data\n",
        "\n",
        "        # Total number of labels\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the test images: {accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1yk3RH9mXU_",
        "outputId": "cf6fb774-3951-41a5-eac3-7f5e5cc06e90"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 93.65%\n"
          ]
        }
      ]
    }
  ]
}